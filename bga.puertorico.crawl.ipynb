{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import concurrent.futures\n",
    "\n",
    "from lxml import html\n",
    "from IPython.display import JSON,HTML\n",
    "\n",
    "from jsonpath_rw import jsonpath, parse\n",
    "import jsonpath_rw_ext as jsonp\n",
    "import collections\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from json import JSONEncoder, JSONDecoder\n",
    "import pickle\n",
    "\n",
    "class PythonObjectEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (list, dict, str, unicode, int, float, bool, type(None))):\n",
    "            return JSONEncoder.default(self, obj)\n",
    "        return {'_python_object': pickle.dumps(obj)}\n",
    "\n",
    "def as_python_object(dct):\n",
    "    if '_python_object' in dct:\n",
    "        return pickle.loads(str(dct['_python_object']))\n",
    "    return dct\n",
    "\n",
    "def save_to_json_file(filename, content):\n",
    "    temp = json.dumps(content, cls=PythonObjectEncoder)\n",
    "    return save_to_file(filename, temp)\n",
    "\n",
    "def save_to_file(filename, content):\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(content)\n",
    "    return \"saved \" + filename    \n",
    "\n",
    "def load_from_json_file(file_name):\n",
    "    content = load_from_file(file_name)\n",
    "    result = json.load(content, object_hook=as_python_object)\n",
    "    return result\n",
    "\n",
    "def load_from_file(file_name):\n",
    "    content = open(file_name)\n",
    "    return content\n",
    "\n",
    "def as_json(content):\n",
    "    return json.loads(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_all(key):\n",
    "    return lambda data: jsonp.match(key, data)\n",
    "\n",
    "def select_one(key):\n",
    "    return lambda data: jsonp.match1(key, data)\n",
    "\n",
    "def contains(key, value):\n",
    "    return lambda data: jsonp.match1(key, data) == value\n",
    "\n",
    "def all_of(*filters):\n",
    "    def fn(data):\n",
    "        for f in filters:\n",
    "            if not f(data):\n",
    "                return False\n",
    "        return True  \n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = [1, 5, 20, 100, 500, 1000]\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "def print_progress(i, timer_log=None, total=None):\n",
    "    if (i % points[0] == 0):\n",
    "        if i > 0 and (i % points[1] == 0):\n",
    "            sys.stdout.write(' ')\n",
    "            if (i % points[2] == 0):\n",
    "                sys.stdout.write('  ')\n",
    "                if (i % points[3] == 0):\n",
    "                    sys.stdout.write('\\n')\n",
    "                    if (i % points[4] == 0):\n",
    "                        sys.stdout.write('\\n')\n",
    "                        if total and (i % points[5] == 0):                            \n",
    "                            timer_log = print_stats(total, i, points[5], timer_log)\n",
    "        sys.stdout.write('.')\n",
    "        sys.stdout.flush()   \n",
    "        \n",
    "def print_stats(total, processed, bunch, last_time, **kwargs):\n",
    "    now = time.time()\n",
    "    speed = (now-last_time)/60.0/bunch\n",
    "    eta = speed*(total-processed)\n",
    "    print('speed: {speed:.1f} min/bunch, eta: {eta:.2f} min\\n'.format(speed = speed, eta = eta, **kwargs))\n",
    "    return now\n",
    "\n",
    "def with_progress(l, size=None):\n",
    "    for i,v in enumerate(l):\n",
    "        print_progress(i, time.time(), size)\n",
    "        yield v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_latest_tables(batch, from_time, from_id=1):\n",
    "    url = site + '/message/board?type=lastresult&social=false&dojo.preventCache=1537975056450&id=14'+\\\n",
    "        '&page=0&per_page={per_page}&from_time={from_time}&from_id={from_id}'.format(per_page=batch, from_id=from_id, from_time=from_time)\n",
    "    page = s.get(url).text\n",
    "    return as_json(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(amout, from_time=1550000000):\n",
    "    result = []\n",
    "    x = load_latest_tables(amout, from_time)\n",
    "    for t in x['data']:\n",
    "        tree = html.fromstring(t['html'])\n",
    "        ll = tree.xpath('//a/@href')\n",
    "        ids = [l[l.find('=')+1:] for l in ll]\n",
    "        (ids[0], ids[1], len(ids)-1, t['timestamp'])\n",
    "        result.append({\n",
    "            'table': ids[0], \n",
    "            'player': ids[1], \n",
    "            'player_amount': len(ids)-1, \n",
    "            'timestamp': t['timestamp']\n",
    "        })\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_iterator(stop=30, batch=5000, ts=1550000000):\n",
    "#     print('starting with ' + str(dict(stop=stop, batch=batch, ts = ts)))\n",
    "    for i in range(stop // batch):\n",
    "        for t in load_batch(batch, ts):\n",
    "            yield t\n",
    "        if t:\n",
    "            ts = t['timestamp']\n",
    "        print_progress(i)\n",
    "    for t in load_batch(stop % batch, ts):\n",
    "        yield t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_info(tbl):\n",
    "    url = site + '/table/table/tableinfos.html?id={table}&dojo.preventCache=1537970039954'.format(table=tbl)\n",
    "    page = s.get(url).text\n",
    "    data = as_json(page)['data']\n",
    "    return data\n",
    "\n",
    "def get_table_datas(table, player, version):\n",
    "    url = site + '/archive/replay/{version}/?table={table}&player={player}&comments=1' \\\n",
    "        .format(table=table, player=player, version=version)\n",
    "    page = s.get(url).text\n",
    "\n",
    "    tree = html.fromstring(page)\n",
    "    nodes = tree.xpath('//div[@id=\"overall-content\"]/script')\n",
    "    if not nodes:\n",
    "        nodes = tree.xpath('//b[@id=\"bga_fatal_error_descr\"]')\n",
    "        raise Exception(nodes[0].text_content())\n",
    "    text = nodes[0].text_content()\n",
    "    \n",
    "    start = text.find('completesetup')\n",
    "    end = text.find('\\n', start)\n",
    "    return as_json('[' +text[start+14:end-2]+']')\n",
    "\n",
    "def get_game_log(table):\n",
    "    url = site + '/archive/archive/logs.html?table={table}&translated=false&dojo.preventCache=1537972617341' \\\n",
    "        .format(table=table)\n",
    "    page = s.get(url).text\n",
    "    return as_json(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(info):\n",
    "    return all_of(\n",
    "        contains('$.options.\"100\".value', '0'),\n",
    "        contains('$.options.\"101\".value', '0'),\n",
    "        contains('$.options.\"102\".value', '0'),\n",
    "        contains('$.options.\"103\".value', '0')                      \n",
    "    )(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_table_datas(table, player):\n",
    "    info = get_table_info(table)\n",
    "    if not valid(info):\n",
    "        return None\n",
    "    datas = get_table_datas(table, player, info['siteversion'])\n",
    "    log = get_game_log(table)\n",
    "    return {\n",
    "        'table': table,\n",
    "        'info': info,\n",
    "        'datas': datas,\n",
    "        'log': log\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_table_datas(table, player, **kvargs):\n",
    "    info = get_table_info(table)\n",
    "    if not valid(info):\n",
    "        return None\n",
    "    return {\n",
    "        'table': table,\n",
    "        'player': player,\n",
    "        'version': info['siteversion']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "def load_table(t):\n",
    "    tbl = t['table']\n",
    "    fn = 'pr/pr_{}.json'.format(tbl)\n",
    "    if os.path.exists(fn):\n",
    "        pass\n",
    "    d = load_table_datas(tbl, t['player'])\n",
    "    if d:\n",
    "        save_to_json_file(fn, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = '/moc.aneraemagdraob.ne//:sptth'[::-1]\n",
    "# user = {'email' : 'tolar', 'password' : 'here'}\n",
    "user = {'email' : 'RMelin', 'password' : 'Melin123', 'email': 'e7087812@nwytg.net'}\n",
    "# user = {'email' : 'RobertNN', 'password' : 'RobertN123', 'email': 'e7107542@nwytg.net'}\n",
    "filename = \"pr_tables.json\"\n",
    "\n",
    "s = requests.Session()\n",
    "s.post(site + 'account/account/login.html', data = user)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "result = load_from_json_file(filename)\n",
    "ts = result[-1]['timestamp'] if result else 1550000000\n",
    "\n",
    "result += [i for i in table_iterator(int(1e4), ts=ts)]\n",
    "print('', len(result))\n",
    "save_to_json_file(filename, result)\n",
    "print(result[-1]) # ('40883526', '1520860289', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [t for t in load_from_json_file(filename) if t['player_amount'] == 4]\n",
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = load_from_json_file('pr_tables.json')\n",
    "len(fd)\n",
    "points = [10, 50, 200, 1000, 10000, 1000]\n",
    "\n",
    "l = [t for t in with_progress(fd, len(fd)) if t['player_amount'] == 4 and valid(get_table_info(t['table']))]\n",
    "save_to_json_file('pr_tables_filtered.json', l)\n",
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls pr | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,t in enumerate(l[1100:1130]):\n",
    "    fn = 'pr/pr_{}.json'.format(t['table'])\n",
    "    if not os.path.exists(fn):\n",
    "        info = get_table_info(t['table'])\n",
    "        if valid(info):\n",
    "            print(1100+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in with_progress(l[1400:1600]):\n",
    "    load_table(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# tar -cvzf pr_4.tgz pr\n",
    "# tar -cvzf pr_tables.tgz pr_tables.json | wc -l\n",
    "tar -xzf pr_tables.tgz\n",
    "tar -xvzf pr_4.tgz | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
